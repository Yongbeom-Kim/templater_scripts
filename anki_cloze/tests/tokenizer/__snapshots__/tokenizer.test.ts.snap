// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`test list.testcase.ts should tokenize "{"clozify_expect": [Function clozify_expect], "description": "Parse nested list of items", "input": "- Front - Back
  - Front = Back
1. Front - Back
  1. Front = Back
  2. Front = Back", "main_expect": [Function main_expect], "parse_expect": [Function parse_expect], "tokenize_expect": [Function tokenize_expect]}" correctly 1`] = `
[
  {
    "col_pos": 0,
    "lexeme": "-",
    "line_pos": 1,
    "type": "punctuation",
  },
  {
    "col_pos": 1,
    "lexeme": " ",
    "line_pos": 1,
    "type": "whitespace",
  },
  {
    "col_pos": 2,
    "lexeme": "Front",
    "line_pos": 1,
    "type": "text",
  },
  {
    "col_pos": 7,
    "lexeme": " ",
    "line_pos": 1,
    "type": "whitespace",
  },
  {
    "col_pos": 8,
    "lexeme": "-",
    "line_pos": 1,
    "type": "punctuation",
  },
  {
    "col_pos": 9,
    "lexeme": " ",
    "line_pos": 1,
    "type": "whitespace",
  },
  {
    "col_pos": 10,
    "lexeme": "Back",
    "line_pos": 1,
    "type": "text",
  },
  {
    "col_pos": 14,
    "lexeme": "
",
    "line_pos": 1,
    "type": "newline",
  },
  {
    "col_pos": 0,
    "lexeme": "  ",
    "line_pos": 2,
    "type": "whitespace",
  },
  {
    "col_pos": 2,
    "lexeme": "-",
    "line_pos": 2,
    "type": "punctuation",
  },
  {
    "col_pos": 3,
    "lexeme": " ",
    "line_pos": 2,
    "type": "whitespace",
  },
  {
    "col_pos": 4,
    "lexeme": "Front",
    "line_pos": 2,
    "type": "text",
  },
  {
    "col_pos": 9,
    "lexeme": " ",
    "line_pos": 2,
    "type": "whitespace",
  },
  {
    "col_pos": 10,
    "lexeme": "=",
    "line_pos": 2,
    "type": "punctuation",
  },
  {
    "col_pos": 11,
    "lexeme": " ",
    "line_pos": 2,
    "type": "whitespace",
  },
  {
    "col_pos": 12,
    "lexeme": "Back",
    "line_pos": 2,
    "type": "text",
  },
  {
    "col_pos": 16,
    "lexeme": "
",
    "line_pos": 2,
    "type": "newline",
  },
  {
    "col_pos": 0,
    "lexeme": "1",
    "line_pos": 3,
    "type": "number",
  },
  {
    "col_pos": 1,
    "lexeme": ".",
    "line_pos": 3,
    "type": "punctuation",
  },
  {
    "col_pos": 2,
    "lexeme": " ",
    "line_pos": 3,
    "type": "whitespace",
  },
  {
    "col_pos": 3,
    "lexeme": "Front",
    "line_pos": 3,
    "type": "text",
  },
  {
    "col_pos": 8,
    "lexeme": " ",
    "line_pos": 3,
    "type": "whitespace",
  },
  {
    "col_pos": 9,
    "lexeme": "-",
    "line_pos": 3,
    "type": "punctuation",
  },
  {
    "col_pos": 10,
    "lexeme": " ",
    "line_pos": 3,
    "type": "whitespace",
  },
  {
    "col_pos": 11,
    "lexeme": "Back",
    "line_pos": 3,
    "type": "text",
  },
  {
    "col_pos": 15,
    "lexeme": "
",
    "line_pos": 3,
    "type": "newline",
  },
  {
    "col_pos": 0,
    "lexeme": "  ",
    "line_pos": 4,
    "type": "whitespace",
  },
  {
    "col_pos": 2,
    "lexeme": "1",
    "line_pos": 4,
    "type": "number",
  },
  {
    "col_pos": 3,
    "lexeme": ".",
    "line_pos": 4,
    "type": "punctuation",
  },
  {
    "col_pos": 4,
    "lexeme": " ",
    "line_pos": 4,
    "type": "whitespace",
  },
  {
    "col_pos": 5,
    "lexeme": "Front",
    "line_pos": 4,
    "type": "text",
  },
  {
    "col_pos": 10,
    "lexeme": " ",
    "line_pos": 4,
    "type": "whitespace",
  },
  {
    "col_pos": 11,
    "lexeme": "=",
    "line_pos": 4,
    "type": "punctuation",
  },
  {
    "col_pos": 12,
    "lexeme": " ",
    "line_pos": 4,
    "type": "whitespace",
  },
  {
    "col_pos": 13,
    "lexeme": "Back",
    "line_pos": 4,
    "type": "text",
  },
  {
    "col_pos": 17,
    "lexeme": "
",
    "line_pos": 4,
    "type": "newline",
  },
  {
    "col_pos": 0,
    "lexeme": "  ",
    "line_pos": 5,
    "type": "whitespace",
  },
  {
    "col_pos": 2,
    "lexeme": "2",
    "line_pos": 5,
    "type": "number",
  },
  {
    "col_pos": 3,
    "lexeme": ".",
    "line_pos": 5,
    "type": "punctuation",
  },
  {
    "col_pos": 4,
    "lexeme": " ",
    "line_pos": 5,
    "type": "whitespace",
  },
  {
    "col_pos": 5,
    "lexeme": "Front",
    "line_pos": 5,
    "type": "text",
  },
  {
    "col_pos": 10,
    "lexeme": " ",
    "line_pos": 5,
    "type": "whitespace",
  },
  {
    "col_pos": 11,
    "lexeme": "=",
    "line_pos": 5,
    "type": "punctuation",
  },
  {
    "col_pos": 12,
    "lexeme": " ",
    "line_pos": 5,
    "type": "whitespace",
  },
  {
    "col_pos": 13,
    "lexeme": "Back",
    "line_pos": 5,
    "type": "text",
  },
]
`;

exports[`test text.testcase.ts should tokenize "{"clozify_expect": [Function clozify_expect], "description": "Mixed whitespace and newlines", "input": " 	 
 	 ", "main_expect": [Function main_expect], "parse_expect": [Function parse_expect], "tokenize_expect": [Function tokenize_expect]}" correctly 1`] = `
[
  {
    "col_pos": 0,
    "lexeme": " 	 ",
    "line_pos": 1,
    "type": "whitespace",
  },
  {
    "col_pos": 3,
    "lexeme": "
",
    "line_pos": 1,
    "type": "newline",
  },
  {
    "col_pos": 0,
    "lexeme": " 	 ",
    "line_pos": 2,
    "type": "whitespace",
  },
]
`;

exports[`test text.testcase.ts should tokenize "{"clozify_expect": [Function clozify_expect], "description": "Multiple newlines", "input": "

", "main_expect": [Function main_expect], "parse_expect": [Function parse_expect], "tokenize_expect": [Function tokenize_expect]}" correctly 1`] = `
[
  {
    "col_pos": 0,
    "lexeme": "

",
    "line_pos": 1,
    "type": "newline",
  },
]
`;

exports[`test text.testcase.ts should tokenize "{"clozify_expect": [Function clozify_expect], "description": "Simple text with newline", "input": "Hello 123
World", "main_expect": [Function main_expect], "parse_expect": [Function parse_expect], "tokenize_expect": [Function tokenize_expect]}" correctly 1`] = `
[
  {
    "col_pos": 0,
    "lexeme": "Hello",
    "line_pos": 1,
    "type": "text",
  },
  {
    "col_pos": 5,
    "lexeme": " ",
    "line_pos": 1,
    "type": "whitespace",
  },
  {
    "col_pos": 6,
    "lexeme": "123",
    "line_pos": 1,
    "type": "number",
  },
  {
    "col_pos": 9,
    "lexeme": "
",
    "line_pos": 1,
    "type": "newline",
  },
  {
    "col_pos": 0,
    "lexeme": "World",
    "line_pos": 2,
    "type": "text",
  },
]
`;

exports[`test text.testcase.ts should tokenize "{"clozify_expect": [Function clozify_expect], "description": "Simple text with numbers", "input": "123 456", "main_expect": [Function main_expect], "parse_expect": [Function parse_expect], "tokenize_expect": [Function tokenize_expect]}" correctly 1`] = `
[
  {
    "col_pos": 0,
    "lexeme": "123",
    "line_pos": 1,
    "type": "number",
  },
  {
    "col_pos": 3,
    "lexeme": " ",
    "line_pos": 1,
    "type": "whitespace",
  },
  {
    "col_pos": 4,
    "lexeme": "456",
    "line_pos": 1,
    "type": "number",
  },
]
`;

exports[`test text.testcase.ts should tokenize "{"clozify_expect": [Function clozify_expect], "description": "Text with mixed whitespace and newlines", "input": "Hello 123
 	World
456", "main_expect": [Function main_expect], "parse_expect": [Function parse_expect], "tokenize_expect": [Function tokenize_expect]}" correctly 1`] = `
[
  {
    "col_pos": 0,
    "lexeme": "Hello",
    "line_pos": 1,
    "type": "text",
  },
  {
    "col_pos": 5,
    "lexeme": " ",
    "line_pos": 1,
    "type": "whitespace",
  },
  {
    "col_pos": 6,
    "lexeme": "123",
    "line_pos": 1,
    "type": "number",
  },
  {
    "col_pos": 9,
    "lexeme": "
",
    "line_pos": 1,
    "type": "newline",
  },
  {
    "col_pos": 0,
    "lexeme": " 	",
    "line_pos": 2,
    "type": "whitespace",
  },
  {
    "col_pos": 2,
    "lexeme": "World",
    "line_pos": 2,
    "type": "text",
  },
  {
    "col_pos": 7,
    "lexeme": "
",
    "line_pos": 2,
    "type": "newline",
  },
  {
    "col_pos": 0,
    "lexeme": "456",
    "line_pos": 3,
    "type": "number",
  },
]
`;

exports[`test text.testcase.ts should tokenize "{"clozify_expect": [Function clozify_expect], "description": "Text with multiple newlines", "input": "Multiple


Newlines


", "main_expect": [Function main_expect], "parse_expect": [Function parse_expect], "tokenize_expect": [Function tokenize_expect]}" correctly 1`] = `
[
  {
    "col_pos": 0,
    "lexeme": "Multiple",
    "line_pos": 1,
    "type": "text",
  },
  {
    "col_pos": 8,
    "lexeme": "


",
    "line_pos": 1,
    "type": "newline",
  },
  {
    "col_pos": 0,
    "lexeme": "Newlines",
    "line_pos": 4,
    "type": "text",
  },
  {
    "col_pos": 8,
    "lexeme": "


",
    "line_pos": 4,
    "type": "newline",
  },
]
`;

exports[`test text.testcase.ts should tokenize "{"clozify_expect": [Function clozify_expect], "description": "Whitespace characters", "input": " 	 ", "main_expect": [Function main_expect], "parse_expect": [Function parse_expect], "tokenize_expect": [Function tokenize_expect]}" correctly 1`] = `
[
  {
    "col_pos": 0,
    "lexeme": " 	 ",
    "line_pos": 1,
    "type": "whitespace",
  },
]
`;
